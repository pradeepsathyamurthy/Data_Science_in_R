}
############################################################################################################
# cacheSolve - Function which is used to calculate the matirx inverse
# This object will refer the objects of makeCacheMatrix with the help of lexical scoping funtionality
# If we pass the same matrix, inverse matrix of it which is cached will be passed by makeCacheMatrix object
# If for new value, then it will pass NULL and its respective inverse value is calculated in this cacheSolve function
############################################################################################################
# creating a function cacheSolve which will carry an argument in it
cacheSolve <- function(m){
# we are trying to get the value of matrix inverse for the matrix passed if stored in cache (i.e in the makeCacheMatrix environment) through lexical scoping
# we try to access the getter method of inverse matrix, getmatrix() in makeCacheMatrix environment
# Through lexical scoping it would get the value of inverse of a same matrix passed whose value if stored in cache
inverse_matrix <- m$getmatrix()
# We see if the value is already cached in makeCacheMatrix environment
# If valid value is stored we are passing that value with no further manipulation
# If it is null we will skip without returning any values and try to manupulate inverse of matrix outsie the if loop
if(!is.null(inverse_matrix)){
print("fetching value from cache")
return(inverse_matrix)
}
# If in case the inverse matrix value is not available in cache, then we need to compute it
# Thus, inorder to compute inverse of a matrix we need a valid square matrix
# So, we are trying to fetch the data of matrix passed by the user from makeCacheMatrix object
matrix_data <- m$get()
# Once the matrix data is obtained, we use solve() function to find the inverse matrix of it
inverse_matrix <- solve(matrix_data)
# Once the inverse of a matrix is computed, we set its value in makeCacheMatrix object using setmatrix function
m$setmatrix(inverse_matrix)
# Now that the value is cached, we are returning the value if inverse matrix found.
return(inverse_matrix)
}
############################################################################################################
# Creating a square matrix and Executing the above function to check
# creating a 4x4 square matrix using rbind function
############################################################################################################
x1=c(4,2,6,6)
x2=c(5,-5,6,0)
x3=c(-5,-3,-4,4)
x4=c(5,1,6,-5)
m=rbind(x1,x2,x3,x4)
############################################################################################################
# I have switched on the debuger to validate the navigation of the function and how the lexical scoping takes place
# Kindly u can enable it if interested by removing # from below two lines
############################################################################################################
# debug(cacheSolve)
# debug(makeCacheMatrix)
############################################################################################################
# Passing a Matrix to find a inverse of it using lexical scoping
############################################################################################################
cacheSolve(makeCacheMatrix(m))
str(str)
ls
str(ls)
str(lm)
x <- 1:10
str(x)
summary(x)
x <- 1:1000
summary(x) # this generally discribe the object x in a statistical form, that is by giving 5 number summary
str(x) # str is similar to summary. However, it descrive he object x generally, saying it is a int with certain values
?lm
?gl
x <- gl(10,3)
x
summary(x)
str(x)
load(dataset)
load("dataset")
library(datasets)
data <- airquality
head(data)
str(data)
summary(data)
s <- split(data,data$Month)
s
str(s)
summary(s)
m <- matrix(1:20, nrow = "2", ncol = "10")
m <- matrix(1:20, nrow = 2, ncol = 10)
m
summary(m)
str(m)
head(data)
str(data)
summary(data)
m <- matrix(1:20, nrow = 2, ncol = 10)
summary(m) #
str(m)
m
m[,1]
m[1,]
s <- split(data,data$Month)
str(s)
summary(s)
random.num1 <- rnorm(20)
summary(random.num1)
random.num1
random.num2 <- rnorm(20,10,2)
random.num2
random.num2
summary(random.num2)
sd(random.num2)
rpois(10)
rpois(10,1)
ppois(10,1)
ppois(2,2)
beta0 <- 0.5
beta1 <- 2
x <- rnorm(100)
error <- rnorm(100,0,2) # this is the noise in data
y <- beta0 + beta1 (x) + error
y <- beta0 + beta1*(x) + error
summary(y)
plot(x,y)
y <- beta0 + beta1*(x)
summary(y)
plot(x,y)
x <- rbinom(100,1,0.5)
x
set.seed(1)
x <- rbinom(100,1,0.5)
x <- rbinom(100,1,0.5)
set.seed(1)
x <- rbinom(100,1,0.5)
error <- rnorm(100,0,2)
y <- beta0 + beta1*(x) + error
summary(y)
plot(x,y) # thus, is we have the infomraiton of slope and intercepts, we can generate few randome variabels and some noise and test it
y <- beta0 + beta1*(x) # if i remove noise it must increase the correaltion
summary(y)
plot(x,y) #shows perfect correlation
set.seed(1)
x <- rnorm(100,0,1)
log.mu <- 0.5 + 0.3*(x)
y <- rpois(100,exp(log.mu))
y
plot(x,y)
set.seed(1)
sample(10)
sample(10)
sample(10)
set.seed(1)
sample(10)
sample(10)
sample(10)
sample(10)
set.seed(1)
sample(letters)
sample(letters,5)
sample(letters,5)
sample(letters,5)
set.seed(1)
sample(letters,5)
sample(letters,5)
set.seed(1)
sample(letters,5)
set.seed(1)
sample(1:10)
sample(1:10)
sample(1:10)
sample(1:10,replace=TRUE)
sample(1:3,replace=TRUE)
sample(1:20,replace=TRUE)
sample(10) # generate random sample of 10 numbers
sample(letters,5) # generate randome 5 characters of alphabets
f <- function() {for(i in 1:100){
print(pradeep)
}
}
print("hi")
system.time()
f
system.time()
system.time(f)
f
f()
f <- function() {for(i in 1:100){
print("pradeep")
}
}
f()
system.time(f())
system.time(f())
system.time(f())
system.time(f())
load("D:/Courses/CSC423 - SAS & R - Data Analysis and Regression/SAS/Project/Project_R_Data.RData")
str(train)
model.temp <- lm(count~season+holiday+workingday+weather+temp+humidity+windspeed+casual+
hour+day+year, data = train)
summary(model.temp)
model_bckwrd <- step(model.temp,direction = "backward")
summary(model_bckwrd)
model_stepwise <- step(model.temp,direction = "both")
summary(model_stepwise)
plot(model.temp)
require(MPV)
require(MPV)
PRESS(model.temp)
PRESS(model_stepwise)
temp_predict = predict(model.temp,test)
boxplot(train$count~train$weather,xlab="Weather", ylab="count of users")
boxplot(train$count~train$weather,xlab="Count Predicted", ylab="Count Observed")
load("D:/Courses/CSC423 - SAS & R - Data Analysis and Regression/SAS/Project/Project_R_Data.RData")
train$hour=as.integer(train$hour)
test$hour=as.integer(test$hour)
require(rpart)
require(rattle)#these libraries will be used to get a good visual plot for the decision tree model. 
require(rpart.plot)
require(RColorBrewer)
require(rpart)
require(rattle)#these libraries will be used to get a good visual plot for the decision tree model. 
require(rpart.plot)
require(RColorBrewer)
d=rpart(registered~hour,data=train)
fancyRpartPlot(d)
data=rbind(train,test)
data$dp_reg=0
data$dp_reg[data$hour<8]=1
data$dp_reg[data$hour>=22]=2
data$dp_reg[data$hour>9 & data$hour<18]=3
data$dp_reg[data$hour==8]=4
data$dp_reg[data$hour==9]=5
data$dp_reg[data$hour==20 | data$hour==21]=6
data$dp_reg[data$hour==19 | data$hour==18]=7
data$year_part[data$year=='2011']=1
data$year_part[data$year=='2011' & data$month>3]=2
data$year_part[data$year=='2011' & data$month>6]=3
data$year_part[data$year=='2011' & data$month>9]=4
data$year_part[data$year=='2012']=5
data$year_part[data$year=='2012' & data$month>3]=6
data$year_part[data$year=='2012' & data$month>6]=7
data$year_part[data$year=='2012' & data$month>9]=8
table(data$year_part)
data$day_type=""
data$day_type[data$holiday==0 & data$workingday==0]="weekend"
data$day_type[data$holiday==1]="holiday"
data$day_type[data$holiday==0 & data$workingday==1]="working day"
data$weekend=0
data$weekend[data$day=="Sunday" | data$day=="Saturday" ]=1
data$weekend=0
data$weekend[data$day=="Sunday" | data$day=="Saturday"]=1
View(data)
train$hour=as.factor(train$hour)
test$hour=as.factor(test$hour)
set.seed(415)
fit1 <- randomForest(logreg ~ hour +workingday+day+holiday+ day_type +temp_reg+humidity+atemp+windspeed+season+weather+dp_reg+weekend+year+year_part, data=train,importance=TRUE, ntree=250)
str(data)
str(train)
d=rpart(registered~hour,data=test)
fancyRpartPlot(d)
d=rpart(registered~hour,data=train)
e=rpart(casual~hour,data=train)
fancyRpartPlot(e)
data=rbind(train,test)
data$dp_cas=0
data$dp_cas[data$hour>0 & data$hour<9]=1
data$dp_cas[data$hour>8 & data$hour<11]=2
data$dp_cas[data$hour>10 & data$hour<21]=3
data$dp_cas[data$hour>20 & data$hour<25]=4
train$hour=as.integer(train$hour) # convert hour to integer
test$hour=as.integer(test$hour) # modifying in both train and test data set
e=rpart(casual~hour,data=train)
fancyRpartPlot(e)
data=rbind(train,test)
data$dp_cas=0
data$dp_reg[data$hour==8]=1
data$dp_reg[data$hour==9]=2
data$dp_reg[data$hour==20 | data$hour==21]=3
data$dp_reg[data$hour==19 | data$hour==18]=4
load("D:/Courses/CSC423 - SAS & R - Data Analysis and Regression/SAS/Project/Project_R_Data.RData")
train$hour=as.integer(train$hour) # convert hour to integer
test$hour=as.integer(test$hour) # modifying in both train and test data set
require(rpart)
require(rattle)#these libraries will be used to get a good visual plot for the decision tree model
require(rpart.plot)
require(RColorBrewer)
d=rpart(registered~hour,data=train)
fancyRpartPlot(d)
# Nodes Creation - brought down from 24 levels of hours to 8 levels
data=rbind(train,test)
data$dp_reg=0
data$dp_reg[data$hour<8]=1
data$dp_reg[data$hour>=22]=2
data$dp_reg[data$hour>9 & data$hour<18]=3
data$dp_reg[data$hour==8]=4
data$dp_reg[data$hour==9]=5
data$dp_reg[data$hour==20 | data$hour==21]=6
data$dp_reg[data$hour==19 | data$hour==18]=7
e=rpart(casual~hour,data=train)
fancyRpartPlot(e)
data$dp_cas=0
data$dp_cas[data$hour==8]=1
data$dp_cas[data$hour==9]=2
data$dp_cas[data$hour==20 | data$hour==21]=3
data$dp_cas[data$hour==19 | data$hour==18]=4
data$year_part[data$year=='2011']=1
data$year_part[data$year=='2011' & data$month>3]=2
data$year_part[data$year=='2011' & data$month>6]=3
data$year_part[data$year=='2011' & data$month>9]=4
data$year_part[data$year=='2012']=5
data$year_part[data$year=='2012' & data$month>3]=6
data$year_part[data$year=='2012' & data$month>6]=7
data$year_part[data$year=='2012' & data$month>9]=8
table(data$year_part)
data$day_type=""
data$day_type[data$holiday==0 & data$workingday==0]="weekend"
data$day_type[data$holiday==1]="holiday"
data$day_type[data$holiday==0 & data$workingday==1]="working day"
data$weekend=0
data$weekend[data$day=="Sunday" | data$day=="Saturday"]=1
train=data[as.integer(substr(data$datetime,9,10))<20,]
test=data[as.integer(substr(data$datetime,9,10))>19,]
train$hour=as.factor(train$hour)
test$hour=as.factor(test$hour)
str(train)
set.seed(415)
install.packages("randomForest")
logreg <- log(test$registered)
logcas <- log(test$casual)
train$logreg <- log(test$registered)
train$logcas <- log(test$casual)
train$logreg <- ln(test$registered)
train$logreg <- log2(test$registered)
train$logreg <- log2(train$registered)
train$logcas <- log2(train$casual)
logcas <- NULL
logreg <- NULL
fit1 <- randomForest(logreg ~ hour +workingday+day+holiday+ day_type +temp_reg+humidity+atemp+windspeed+
season+weather+dp_reg+weekend+year+year_part, data=train,importance=TRUE, ntree=250)
require(randomForest)
require(randomForest)
fit1 <- randomForest(logreg ~ hour +workingday+day+holiday+ day_type +temp_reg+humidity+atemp+windspeed+
season+weather+dp_reg+weekend+year+year_part, data=train,importance=TRUE, ntree=250)
View(train)
View(train)
str(train)
fit1 <- randomForest(logreg ~ hour +workingday+day+holiday+ day_type +temp+humidity+atemp+windspeed+
season+weather+dp_reg+weekend+year+year_part, data=train,importance=TRUE, ntree=250)
fit1 <- lm(logreg ~ hour +workingday+day+holiday+ day_type +temp+humidity+atemp+windspeed+
season+weather+dp_reg+weekend+year+year_part, data=train,importance=TRUE, ntree=250)
fit1 <- lm(logreg ~ hour +workingday+day+holiday+ day_type +temp+humidity+atemp+windspeed+
season+weather+dp_reg+weekend+year+year_part, data=train)
str(train)
train$day_type=as.factor(train$day_type)
str(train)
fit1 <- lm(logreg ~ hour +workingday+day+holiday+ day_type +temp+humidity+atemp+windspeed+
season+weather+dp_reg+weekend+year+year_part, data=train)
fit1 <- lm(registered ~ hour +workingday+day+holiday+ day_type +temp+humidity+atemp+windspeed+
season+weather+dp_reg+weekend+year+year_part, data=train)
summary(fit1)
fit1 <- lm(registered ~ workingday+day+holiday+ day_type +temp+humidity+windspeed+
season+weather+dp_reg+weekend+year+year_part, data=train)
summary(fit1)
fit2 <- step(fit1,direction = "backward")
summ_fit2 <- summary(fit2);summ_fit2
fit1 <- lm(registered ~ workingday+holiday+ day_type +temp+humidity+windspeed+
season+weather+dp_reg+weekend+year+year_part, data=train)
summary(fit1)
fit1 <- lm(registered ~ workingday+holiday+ temp+humidity+windspeed+
season+weather+dp_reg+weekend+year+year_part, data=train)
summary(fit1)
fit3 <- lm(count~season+holiday+workingday+weather+temp+casual+
hour+day+year, data = train)
summary(fit3)
fit3 <- lm(count~season+holiday+workingday+weather+temp+casual+
hour+year, data = train)
summary(fit3)
fit3 <- lm(log(count)~season+holiday+workingday+weather+temp+casual+
hour+year, data = train)
summary(fit3)
fit3 <- lm(log(count)~season+holiday+workingday+weather+temp+casual+
hour+day+year, data = train)
summary(fit3)
plot(fit3)
fit4 <- step(fit3,direction = "backward")
summary(fit4)
install.packages("dplyr")
install.packages("circlize")
require(dplyr)
require(circlize)
# Create Fake Flight Information in a table
orig = c("IE","GB","US","ES","FI","US","IE","IE","GB")
dest = c("FI","FI","ES","ES","US","US","FI","US","IE")
mydf = data.frame(orig, dest)
# Create a Binary Matrix Based on mydf
mymat <- data.matrix(as.data.frame.matrix(table(mydf)))
# create the objects you want to link from to in your diagram
from <- rownames(mymat)
to <- colnames(mymat)
# Create Diagram by suppling the matrix
par(mar = c(1, 1, 1, 1))
chordDiagram(mymat, order = sort(union(from, to)), directional = TRUE)
circos.clear()
data.need <- cbind(final.chi.plot$id,final.chi.plot$name)
data.need.df <- as.data.frame(data.need)
data.need.unique <- unique(data.need.df)
data.need.order <- order(data.need.unique)
load("D:/Courses/CSC423 - SAS & R - Data Analysis and Regression/SAS/Project/Prady_23Nov2016_Data.RData")
summary(model6.final.std)
setwd("D:/Courses/Coursera/Data Science/Getting and Cleaning Data/trail")
setwd("D:/Courses/Coursera/Data Science/Getting and Cleaning Data/trail")
# Downloading the data
download_URL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(download_URL,destfile = "data_week1.csv")
data_quiz1 <- read.csv("data_week1.csv")
View(data_quiz1)
data_quiz1 <- read.csv("data_week1.csv",header = TRUE,na.strings = NA)
head(data_quiz1)
str(data_quiz1)
str(data_quiz1$VAL)
head(data_quiz1$VAL,3)
count.prop <- nrows(data_quiz1$VAL>1000000)
count.prop <- nrow(data_quiz1$VAL>1000000)
data_quiz1$VAL>1000000
count.prop <- data_quiz1[,which(data_quiz1$VAL>1000000)]
count.prop <- data_quiz1[,which(data_quiz1$VAL>15)]
count.prop <- data_quiz1[which(data_quiz1$VAL>15),]
count.prop <- data_quiz1[which(data_quiz1$VAL>1000000),]
count.prop <- data_quiz1[which(data_quiz1$VAL=24),]
count.prop <- data_quiz1[which(data_quiz1$VAL==24),]
head(data_quiz1$FES)
table(data_quiz1$FES)
require(xlsx)
require(xlsx)
install.packages("XLSX")
install.packages("xlsx")
require(xlsx)
download_URL3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
require(XML)
require(XML)
download_URL3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
require(XML)
data.xml <- xmlTreeParse(download_URL3,isURL = TRUE)
data.xml <- xmlTreeParse(download_URL3)
install.packages("xlsx")
require(xlsx)
data.xml <- xmlTreeParse(download_URL3,useInternalNodes = TRUE)
download_URL3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
data.xml <- xmlTreeParse(download_URL3,useInternalNodes = TRUE)
download_URL3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
require(XML)
xmlTreeParse(download_URL3,useInternalNodes = TRUE)
data.xml <- xmlTreeParse(download_URL3,useInternalNodes = TRUE,method="curl")
require(curl)
URL3 <- geturl(download_URL3)
URL3 <- getURL(download_URL3)
require(curl)
URL3 <- getRelativeURL(download_URL3)
data.xml <- xmlTreeParse(URL3,useInternalNodes = TRUE)
install.packages("RCurl")
require(RCurl)
URL3 <- getURL(download_URL3)
data.xml <- xmlTreeParse(URL3,useInternalNodes = TRUE)
xmlRoot(data.xml)
data.root <- xmlRoot(data.xml)
names(data.root)
xmlName(data.root)
data.root[2]
data.root[[2]]
data.root[[2]][[2]]
xmlSApply(data.root,xmlValue)
xpathSApply(data.root,"//zipcode",xmlValue)
zip_filtered <- xpathSApply(data.root,"//li[@class='zipcode']",xmlValue)
zip_filtered <- xpathSApply(data.root,"//zipcode",xmlValue)
zip_filter <- zip_filtered[,which(zip_filtered=="21231")]
zip_filter <- which(zip_filtered=="21231")
zip_count <- nrow(zip_filter)
print(zip_count)
zip_count <- length(zip_filter)
print(zip_count)
data_quest3 <- read.csv("gov_NGAP.csv",header = TRUE,na.strings = NA)
sum(data_quest3$Zip*data_quest3$Ext,na.rm=T)
download.file(url4,"quest5.csv")
url4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(url4,"quest5.csv")
data.read <- fread(quest5.csv)
install.packages("data.table")
data.read <- fread(quest5.csv)
data.read <- read.csv("ques_5.csv")
data.read <- read.csv("quest5.csv")
require(data.table)
data.fread <- fread("quest5.csv")
system.time(DT[,mean(pwgtp15),by=SEX])
DT <- fread("quest5.csv")
system.time(DT[,mean(pwgtp15),by=SEX])
DT[,mean(pwgtp15),by=SEX]
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(mean(DT$pwgtp15,by=DT$SEX))
mean(DT$pwgtp15,by=DT$SEX
mean(DT$pwgtp15,by=DT$SEX)
mean(DT$pwgtp15,by=DT$SEX)
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
tapply(DT$pwgtp15,DT$SEX,mean)
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
sapply(split(DT$pwgtp15,DT$SEX),mean)
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
DT[,mean(pwgtp15),by=SEX]
tapply(DT$pwgtp15,DT$SEX,mean)
sapply(split(DT$pwgtp15,DT$SEX),mean)
View(data_quiz1)
data_quiz1 <- read.csv("data_week1.csv",header = TRUE)
View(data_quiz1)
install.packages("openxlsx")
require(xlsx)
require(openxlsx)
data3 <- read.xlsx("getdata_data_DATA.gov_NGAP.xlsx")
